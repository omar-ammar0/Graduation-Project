{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install torchxrayvision",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import torchxrayvision as xrv"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "seed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seed(42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "dataset_path = '/kaggle/input/knee-dataset2/Dataset knee'\nclass_labels = sorted(os.listdir(dataset_path))\n\nimages = []\nlabels = []\n\nfor label, class_label in enumerate(class_labels):\n    class_path = os.path.join(dataset_path, class_label)\n    for image_name in os.listdir(class_path):\n        images.append(image_name)\n        labels.append(label)\n\nimages = np.array(images)\nlabels = np.array(labels)\n\ndf = pd.DataFrame({'image_id': images, 'label': labels})\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\ntrain_val, test = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\ntrain, validation = train_test_split(train_val, test_size=0.1, stratify=train_val['label'], random_state=42)\n\ntrain = train.reset_index(drop=True)\nvalidation = validation.reset_index(drop=True)\ntest = test.reset_index(drop=True)\nCases = {i: class_label for i, class_label in enumerate(class_labels)}\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "Cases = {}\nfor i in range(len(class_labels)):\n    Cases[i] = class_labels[i]\nprint(Cases)\n\nprint('----------------------------------------------------')\nprint(\"Number of Images in training : \" , len(train))\nprint(\"Number of Images in validation : \" , len(validation))\nprint(\"Number of Images in testing : \" , len(test))\nprint(\"Total Images : \" , len(train)+len(validation)+len(test))\nprint('----------------------------------------------------')\n\n\nx = [\"Train\", \"Test\", \"Validation\"]\ndata = [train , test , validation]\nc = 0\nfor i in data:\n    print(\"----- {} -----\".format(x[c]))\n    for j in Cases:\n        print(\"{}: {}\".format(Cases[j],len(i[i[\"label\"] == j])))\n    c += 1",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# DenseNet",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class CustomDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(dataset_path, Cases[self.df.iloc[idx, 1]], self.df.iloc[idx, 0])\n        image = Image.open(img_name).convert(\"RGB\")\n        img = image.convert('L')\n\n        if self.transform:\n            img = self.transform(img)\n\n        img = img * 2048 - 1024\n        label = self.df.iloc[idx, 1]\n        return img, label",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    #transforms.RandomRotation(15),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntrain_dataset = CustomDataset(train, transform=train_transform)\nvalidation_dataset = CustomDataset(validation, transform=test_transform)\ntest_dataset = CustomDataset(test, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nvalidation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\nmodel.op_threshs = None\nmodel.classifier = torch.nn.Linear(1024, 3)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.classifier.parameters(), lr=0.1)\n\ncriterion = nn.CrossEntropyLoss()\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience= 3)\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "EPOCHS = 100\nbest_val_loss = float('inf')\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    running_loss /= len(train_loader.dataset)\n    train_accuracy = 100 * correct_train / total_train\n\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n    val_loss /= len(validation_loader.dataset)\n    val_accuracy = 100 * correct_val / total_val\n    scheduler.step(val_loss)\n\n\n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Training Loss: {running_loss:.4f}, Validation Loss: {val_loss:.4f},Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%, Learning Rate: {current_lr}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\nprint('Accuracy: ', 100 * correct / total, '%')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def normalize_image(image):\n    image_min = image.min()\n    image_max = image.max()\n    image.clamp_(min=image_min, max=image_max)\n    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n    return image",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_images(images, labels, classes, normalize=False):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize=(10, 10))\n\n    for i in range(rows*cols):\n\n        ax = fig.add_subplot(rows, cols, i+1)\n\n        image = images[i]\n\n        if normalize:\n            image_min = image.min()\n            image_max = image.max()\n            image.clamp_(min=image_min, max=image_max)\n            image.add_(-image_min).div_(image_max - image_min + 1e-5)\n\n        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n        ax.set_title(classes[labels[i]])\n        ax.axis('off')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def get_predictions(model, iterator, device):\n\n    model.eval()\n\n    images = []\n    labels = []\n    probs = []\n\n    with torch.no_grad():\n\n        for (x, y) in iterator:\n\n            x = x.to(device)\n\n            y_pred = model(x)\n\n            y_prob = F.softmax(y_pred, dim=-1)\n\n            images.append(x.cpu())\n            labels.append(y.cpu())\n            probs.append(y_prob.cpu())\n\n    images = torch.cat(images, dim=0)\n    labels = torch.cat(labels, dim=0)\n    probs = torch.cat(probs, dim=0)\n\n    return images, labels, probs\n\nimages, labels, probs = get_predictions(model, test_loader, device)\npred_labels = torch.argmax(probs, 1)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_confusion_matrix(labels, pred_labels, classes):\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(1, 1, 1)\n    cm = confusion_matrix(labels, pred_labels)\n    cm = ConfusionMatrixDisplay(cm, display_labels=classes)\n    cm.plot(values_format='d', cmap='Blues', ax=ax)\n    ax.set_title(\"Best Model DenseNet\")\n    plt.xticks(rotation=20)\n\nplot_confusion_matrix(labels, pred_labels, class_labels)\ncorrects = torch.eq(labels, pred_labels)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# ViT",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class CustomDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(dataset_path, Cases[self.df.iloc[idx, 1]], self.df.iloc[idx, 0])\n        image = Image.open(img_name).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        label = self.df.iloc[idx, 1]\n        return image, label",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    #transforms.RandomRotation(15),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ntrain_dataset = CustomDataset(train, transform=train_transform)\nvalidation_dataset = CustomDataset(validation, transform=test_transform)\ntest_dataset = CustomDataset(test, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nvalidation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k')\nmodel = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', config=config)\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.classifier = nn.Linear(model.config.hidden_size, len(class_labels))\n\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n    \ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.1)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=7)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "EPOCHS = 100\nbest_val_loss = float('inf')\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images).logits\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    running_loss /= len(train_loader.dataset)\n    train_accuracy = 100 * correct_train / total_train\n\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).logits\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n    val_loss /= len(validation_loader.dataset)\n    val_accuracy = 100 * correct_val / total_val\n    scheduler.step(val_loss)\n\n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Training Loss: {running_loss:.4f}, Validation Loss: {val_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%, Learning Rate: {current_lr}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model_vit.pth')\n\n    ",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load('best_model_vit.pth'))\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images).logits\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\nprint('Test Accuracy: ', 100 * correct / total, '%')\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def normalize_image(image):\n    image_min = image.min()\n    image_max = image.max()\n    image.clamp_(min=image_min, max=image_max)\n    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n    return image",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_images(images, labels, classes, normalize=False):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize=(10, 10))\n\n    for i in range(rows*cols):\n\n        ax = fig.add_subplot(rows, cols, i+1)\n\n        image = images[i]\n\n        if normalize:\n            image_min = image.min()\n            image_max = image.max()\n            image.clamp_(min=image_min, max=image_max)\n            image.add_(-image_min).div_(image_max - image_min + 1e-5)\n\n        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n        ax.set_title(classes[labels[i]])\n        ax.axis('off')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def get_predictions(model, iterator, device):\n\n    model.eval()\n\n    images = []\n    labels = []\n    probs = []\n\n    with torch.no_grad():\n\n        for (x, y) in iterator:\n\n            x = x.to(device)\n\n            y_pred = model(x).logits\n\n            y_prob = F.softmax(y_pred, dim=-1)\n\n            images.append(x.cpu())\n            labels.append(y.cpu())\n            probs.append(y_prob.cpu())\n\n    images = torch.cat(images, dim=0)\n    labels = torch.cat(labels, dim=0)\n    probs = torch.cat(probs, dim=0)\n\n    return images, labels, probs\n\nimages, labels, probs = get_predictions(model, test_loader, device)\npred_labels = torch.argmax(probs, 1)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_confusion_matrix(labels, pred_labels, classes):\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(1, 1, 1)\n    cm = confusion_matrix(labels, pred_labels)\n    cm_display = ConfusionMatrixDisplay(cm, display_labels=classes)\n    cm_display.plot(values_format='d', cmap='Blues', ax=ax)\n    ax.set_title(\"Best Model ViT\")\n    plt.xticks(rotation=20)\n    \nplot_confusion_matrix(labels, pred_labels, class_labels)\ncorrects = torch.eq(labels, pred_labels)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# ResNet",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class CustomDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(dataset_path, Cases[self.df.iloc[idx, 1]], self.df.iloc[idx, 0])\n        image = Image.open(img_name).convert(\"RGB\")\n        img = image.convert('L')\n\n        if self.transform:\n            img = self.transform(img)\n\n        img = img * 2048 - 1024\n        label = self.df.iloc[idx, 1]\n        return img, label",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.Resize((512, 512)),\n    transforms.ToTensor()\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor()\n])\n\ntrain_dataset = CustomDataset(train, transform=train_transform)\nvalidation_dataset = CustomDataset(validation, transform=test_transform)\ntest_dataset = CustomDataset(test, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nvalidation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = xrv.models.ResNet(weights=\"resnet50-res512-all\")\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "EPOCHS = 100\nbest_val_loss = float('inf')\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    running_loss /= len(train_loader.dataset)\n    train_accuracy = 100 * correct_train / total_train\n\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for images, labels in validation_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n    val_loss /= len(validation_loader.dataset)\n    val_accuracy = 100 * correct_val / total_val\n    scheduler.step(val_loss)\n\n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Training Loss: {running_loss:.4f}, Validation Loss: {val_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%, Learning Rate: {current_lr}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model_resnet.pth')\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load('best_model_resnet.pth'))\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\nprint('Accuracy: ', 100 * correct / total, '%')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def normalize_image(image):\n    image_min = image.min()\n    image_max = image.max()\n    image.clamp_(min=image_min, max=image_max)\n    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n    return image",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_images(images, labels, classes, normalize=False):\n\n    n_images = len(images)\n\n    rows = int(np.sqrt(n_images))\n    cols = int(np.sqrt(n_images))\n\n    fig = plt.figure(figsize=(10, 10))\n\n    for i in range(rows*cols):\n\n        ax = fig.add_subplot(rows, cols, i+1)\n\n        image = images[i]\n\n        if normalize:\n            image_min = image.min()\n            image_max = image.max()\n            image.clamp_(min=image_min, max=image_max)\n            image.add_(-image_min).div_(image_max - image_min + 1e-5)\n\n        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n        ax.set_title(classes[labels[i]])\n        ax.axis('off')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def get_predictions(model, iterator, device):\n\n    model.eval()\n\n    images = []\n    labels = []\n    probs = []\n\n    with torch.no_grad():\n\n        for (x, y) in iterator:\n\n            x = x.to(device)\n\n            y_pred = model(x)\n\n            y_prob = F.softmax(y_pred, dim=-1)\n\n            images.append(x.cpu())\n            labels.append(y.cpu())\n            probs.append(y_prob.cpu())\n\n    images = torch.cat(images, dim=0)\n    labels = torch.cat(labels, dim=0)\n    probs = torch.cat(probs, dim=0)\n\n    return images, labels, probs\n\nimages, labels, probs = get_predictions(model, test_loader, device)\npred_labels = torch.argmax(probs, 1)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_confusion_matrix(labels, pred_labels, classes):\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(1, 1, 1)\n    cm = confusion_matrix(labels, pred_labels)\n    cm = ConfusionMatrixDisplay(cm, display_labels=classes)\n    cm.plot(values_format='d', cmap='Blues', ax=ax)\n    ax.set_title(\"Best Model Resnet\")\n    plt.xticks(rotation=20)\n    \nplot_confusion_matrix(labels, pred_labels, class_labels)\ncorrects = torch.eq(labels, pred_labels)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
